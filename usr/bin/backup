#!/usr/bin/python3

import os
import shlex
import sys
from argparse import ArgumentParser
from configparser import ConfigParser
from io import StringIO
from shutil import rmtree
from subprocess import run, CalledProcessError, Popen, PIPE, STDOUT
from time import strftime


TYPE_CUMULATIVE = "cumulative"
TYPE_FULL = "full"
TYPE_INCREMENTAL = "incremental"


def run_buffered_command(command):
    """
    Runs command and streams stdout/stderr to output buffer as it is generated
    """
    with Popen(
        command, shell=isinstance(command, str), stdout=PIPE, stderr=STDOUT, text=True
    ) as process:
        # Read and print stdout to the buffer line by line
        for line in process.stdout:
            print(line, end="")
        # Check the return code, raise CalledProcessError if it is non-zero
        return_code = process.wait()
        if return_code:
            raise CalledProcessError(return_code, command)


def run_direct_command(command):
    """
    Runs command directly to preserve all ANSI sequences
    """
    run(command, shell=isinstance(command, str), check=True)


def run_script(config, phase, run_method):
    """
    Runs all commands for a particular script phase
    """
    for command in config.get(phase, "").splitlines():
        if not command:
            continue
        print(f"Running {phase}: {command}")
        run_method(command)
    print()


def backup(conf_path, run_method):
    """
    Parses the config file, creates rsync command and runs it along with the pre-/post-scripts
    """
    # Read the config. Raises FileNotFoundError if the config file doesn't exist
    config = ConfigParser()
    with open(conf_path, encoding="utf-8") as f:
        config_data = f"[backup]\n{f.read()}"
    config.read_string(config_data)
    config = config["backup"]

    # Sanity-check backup type
    backup_type = config.get("type", None)
    if backup_type not in (TYPE_CUMULATIVE, TYPE_FULL, TYPE_INCREMENTAL):
        raise ValueError(backup_type)

    # Run pre-script
    run_script(config, "pre-script", run_method)

    # Get source and destination directories including trailing slash if not given
    src_dir = os.path.join(config.get("source-dir", None), "")
    dst_dir = os.path.join(config.get("destination-dir", None), "")

    # Create rsync command
    rsync_cmd = ["rsync", "--archive", "--itemize-changes", "--numeric-ids"]
    # Show progress if requested in command line args
    if run_method is run_direct_command:
        rsync_cmd.extend(("--progress", "--human-readable"))
    # Delete files not existing in source for full and incremental backups
    if backup_type != TYPE_CUMULATIVE:
        rsync_cmd.append("--delete-during")
    # Use remote shell
    remote_shell = config.get("remote-shell", None)
    if remote_shell:
        rsync_cmd.extend(("--rsh", remote_shell))
    # Load list if files to include in the backup
    include_from = config.get("include-from", None)
    if include_from:
        rsync_cmd.extend(("--include-from", include_from))
    # Set directory for hardlink sources for incremental backups
    if backup_type == TYPE_INCREMENTAL:
        current_symlink = os.path.join(dst_dir, "current")
        rsync_cmd.extend(("--link-dest", f"{current_symlink}/"))
    # Include extra rsync command arguments
    extra_args = config.get("extra-args", None)
    if extra_args:
        rsync_cmd.extend(shlex.split(extra_args))
    # Append source directory
    rsync_cmd.append(src_dir)
    # Append destination directory
    if backup_type == TYPE_INCREMENTAL:
        # Create a timestamped subdirectory for incremental backup
        current_time = strftime("%Y-%m-%d_%H-%M")
        backup_dir = f"backup_{current_time}"
        inc_dst_dir = os.path.join(dst_dir, backup_dir, "")
        rsync_cmd.append(inc_dst_dir)
    else:
        rsync_cmd.append(os.path.join(dst_dir, ""))

    print(f"Running backup: {shlex.join(rsync_cmd)}")
    # Run the rsync command
    try:
        run_method(rsync_cmd)
    except CalledProcessError as ex:
        # Remove incremental destination dir and re-raise CalledProcessError
        # if rsync didn't finish with allowed return codes
        #   23 = Partial transfer due to error
        #   24 = Partial transfer due to vanished source files
        if ex.returncode not in (23, 24):
            if backup_type == TYPE_INCREMENTAL and os.path.exists(inc_dst_dir):
                rmtree(inc_dst_dir, ignore_errors=True)
            raise
    print()

    # Create "current" symlink pointing to the newest incremental destination dir
    # and remove the oldest backup(s) if the number of backups exceeded threshold
    if backup_type == TYPE_INCREMENTAL:
        # Remove and recreate the symlink
        try:
            os.remove(current_symlink)
        except FileNotFoundError:
            pass
        os.symlink(backup_dir, current_symlink)
        # Remove the oldest backup(s) if the number of backups exceeded retention threshold
        backups = sorted([entry for entry in os.listdir(dst_dir) if entry.startswith("backup")])
        for oldest_inc_dst_dir in backups[: -config.getint("retention", 180)]:
            print(f"Removing old backup: {oldest_inc_dst_dir}")
            rmtree(os.path.join(dst_dir, oldest_inc_dst_dir))

    # Run post-script
    run_script(config, "post-script", run_method)


def main(args=None):
    """
    Main entrypoint
    """
    parser = ArgumentParser(description="Disassembler's rsync backup utility")
    parser.add_argument(
        "-p",
        "--progress",
        action="store_true",
        help="shows script output and progress during transfer",
    )
    parser.add_argument("config", help="specifies config file to be used")
    args = parser.parse_args(args)

    if args.progress:
        run_method = run_direct_command
    else:
        run_method = run_buffered_command
        # Capture stdout and stderr into output buffer
        buffer = StringIO()
        sys.stdout = sys.stderr = buffer

    try:
        backup(args.config, run_method)
    except:
        # If progress was not shown, restore stdout and stderr and replay the output buffer
        # for cron to register it and send via e-mail
        if not args.progress:
            sys.stdout, sys.stderr = sys.__stdout__, sys.__stderr__
            buffer.seek(0)
            print(buffer.read())
        raise


if __name__ == "__main__":
    main()
